---
layout:     post
title:      "Swift & Machine Learning"
subtitle:   "Sobre Recursos Humanos e Florestas Aleat√≥rias"
date:       2017-03-23 00:10:00
author:     "Lucas Farris"
header-img: "img/farris/2017/mata_atlantica.jpg"
category:   Tutorial
---

> Geralmente, quando se fala em aprendizado de m√°quina para mobile, √© mais comum ver c√≥digos escritos em Python ou R, rodando do lado do servidor. No entanto, h√° casos em que compensa mais fazer o processamento localmente (por poder ser feito offline, e n√£o sobrecarregar o server). Por isso o uso de Swift √© justific√°vel. Uns 4 anos atr√°s, eu falaria pra usar o OpenCV rodando nativo em C++, mas os tempos s√£o outros.
>
>Se voc√™, caro leitor, nunca teve contato com intelig√™ncia artificial, n√£o tema; este artigo n√£o assume que voc√™ conhe√ßa previamente nada sobre.

1. ### Resumo

   Vamos juntos, neste artigo, estudar a base de dados sobre Recursos Humanos do *Kaggle*, e criar uma nova implementa√ß√£o do algoritmo Random Forest na linguagem *Swift*. Em termos da linguagem *Swift*, discutiremos *generics*, ponteiros e paraleliza√ß√£o. De Aprendizado de M√°quina, vamos falar de engenharia de features, dados, par√¢metros e valida√ß√£o. Sobre engenharia de algoritmos, vamos ver complexidade, otimiza√ß√£o e estruturas de dados.

2. ### Introdu√ß√£o

   Em termos de frameworks para ML (*machine learning*), o Swift n√£o est√° muito bem. Existem [alguns projetos](https://github.com/josephmisiti/awesome-machine-learning#swift-general-purpose) isolados, mas todos s√£o promessas inacabadas, e nenhum tinha o algoritmo que eu queria usar (*Random Forest*). Logo, como eu n√£o queria incentivar o *black-box* [que j√° rola na √°rea](http://www.ic.unicamp.br/~rocha/pub/papers/2010-sibgrapi-ml-black-boxes.pdf), surgiu este artigo: escrever o algoritmo. Eu n√£o tenho como ressaltar isso o suficiente:

   > E S C R E V A      S E U S      A L G O R I T M O S

   Pra quem quer se aprofundar na √°rea, recomento o livro cl√°ssico [Intelig√™ncia Artificial: uma abordagem moderna](http://aima.cs.berkeley.edu/) e o [curso de Stanford](https://www.coursera.org/learn/machine-learning) (os dois rolavam soltos em pendrives quando eu cursei essa disciplina na universidade).

   Neste artigo, vamos falar sobre Recursos Humanos, e como identificar funcion√°rios que v√£o pedir demiss√£o.

3. ### Sobre homens e dados

   Primeiramente, vamos falar dos nossos dados. A [base de recursos humanos](https://www.kaggle.com/ludobenistant/hr-analytics) √© atualmente (Fev. 2017) a terceira mais votada no Kaggle. Ela tem um sutil *disclaimer*: `This dataset is simulated`. Logo, qualquer informa√ß√£o que tirarmos daqui n√£o deve ser levada muito a s√©rio.

   Antes de qualquer coisa, vamos dar uma limpada na base de dados, uma *engenharia de features*. Isso geralmente consiste em descartar dados menos relevantes, e realizar opera√ß√µes nos dados restantes.

   > Um exemplo maravilhoso de engenharia de *features* est√° [nos dados dos passageiros do Titanic](https://www.kaggle.com/c/titanic). Ao correlacionar as entradas com a sa√≠da, o fator `sobreviveu? Sim ou n√£o`, vemos que as tr√™s informa√ß√µes claramente mais importantes s√£o [Idade, Sexo, Classe]. Mulhers com mais de trinta anos, meninos com menos de dez anos, e passageiros da primeira classe, tem muito mais chances de sobreviver. Todavia, olhando cuidadosamente os nomes dos passageiros, podemos extrair o t√≠tulo dele (ex: Mr., Miss., Mrs.) que se torna uma feature poderos√≠ssima.

   Escrevi um pequeno trecho de c√≥digo em `Python` pra fazer esse trabalho por n√≥s:

   ```python
   #!/usr/bin/env python
   import pandas as pd
   import numpy as np
   df = pd.read_csv('HR.csv')
   df = df.drop(df.columns[[0,5,7,8,9]], axis=1)#kill uninteresting rows
   df.drop_duplicates().to_csv('database.csv', index=False)
   ```

   As colunas `[Satisfa√ß√£o do funcion√°rio, acidentes no trabalho, se foram promovidos recentemente, departamento, sal√°rio]` cont√©m os dados menos [correlacionados](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) com a sa√≠da dos funcion√°rios. Isso nos deixa com os seguintes:

   | Vari√°vel                                 | Correla√ß√£o com Y |
   | ---------------------------------------- | ---------------- |
   | Anos na empresa                          | 0.144822         |
   | M√©dia de horas por m√™s                   | 0.071287         |
   | N√∫mero de projetos realizados            | 0.023787         |
   | √öltima avalia√ß√£o do funcion√°rio pela empresa | 0.006567         |

4. ### 'Florestal Rand√¥mico'

   O algoritmo *Random Forest*, ou como eu o apelido carinhosamente, *Mata Atl√¢ntica*, √© um classificador supervisionado. Em outras palavras, ele divide dados em classes, e precisa saber previamente a classe dos seus dados para aprender a classificar outros. *Classe* √© o tipo do dado, no nosso caso, se o funcion√°rio pediu ou n√£o demiss√£o.

   Em termos simples, ele cria m√∫ltiplas [√°rvores de decis√£o](https://en.wikipedia.org/wiki/Decision_tree), s√≥ que cada √°rvore usa um subconjunto aleat√≥rio de *features*, e depois usamos *[BAgging](https://en.wikipedia.org/wiki/Bootstrap_aggregating)* para decidir entre as √°rvores. Uma verdadeira sacada (*migu√©*) que performa, pasme, impressionantemente bem e r√°pido. Na nossa implementa√ß√£o, vamos dar suporte aos seguintes par√¢metros:

   | Nome                 | Tipo                | Descri√ß√£o                                | Padr√£o   |
   | -------------------- | ------------------- | ---------------------------------------- | -------- |
   | Profundidade M√°xima  | `Int` (1,‚àû)         | Altura m√°xima de cada √°rvore, ou seja, m√°xima dist√¢ncia entre a raiz e as folhas. Aumentar esse n√∫mero deixa o algoritmo mais r√°pido e menos preciso | `10`     |
   | Tamanho M√≠nimo do N√≥ | `Int` (1,‚àû)         | Tamanho m√≠nimo do subconjunto do `dataset` no qual cada n√≥ √© dividido. Aumentar esse n√∫mero deixa o algoritmo mais r√°pido e menos preciso | `50`     |
   | Tamanho de `Sample`  | `Double`(0,1)       | Porcentagem do `dataset` a ser *"sampleada"* em cada √°rvore. Ajuda a deixar cada √°rvore diferente entre si | `0.1`    |
   | N√∫mero de √Årvores    | `Int`(1,‚àû)          | N√∫mero de √°rvores constru√≠das            | `10`     |
   | *Seed*               | `String`            | Semente do gerador de n√∫meros aleat√≥rios | `"Seed"` |
   | Tipo de Split        | `[All, Sqrt, Log2]` | N√∫mero de features usado em cada split. Ajuda a deixar cada √°rvore diferente entre si | `Sqrt`   |

   √Årvores diferentes entre si s√£o o charme do `Random Forest`. Vamos entender isso logo. Eis o pseudo-c√≥digo que vamos implementar:

   ```
   randomForest:
     Seja D o nosso dataset
     Para cada √°rvore a ser constru√≠da:
         seja S um subconjunto de D
         seja A(S) uma raiz de √°rvore
         A.M = obterSplit ( A )
         split ( A )

   obterSplit ( Raiz de √°rvore A ):
   	seja M o melhor split encontrado at√© o momento
   	para cada feature F do split:
   		para cada F[N] a feature de cada linha N de A.S:
   			seja D,E subconjuntos de A.S
   			para cada G[N] a feature de cada linha N de A.S:
   				se G[N]>F[N] adicione G[N] a D
   				caso contr√°rio adicione a E
   			se M'(D,E) for um split melhor que M, M recebe M'(D,E)
   	retorna M

   split  ( N√≥ de √°rvore A ):
   	Se a direita, ou esqurerda do split de A for vazia, retorne n√≥ folha (A.M)
   	Se chegamos na profundidade m√°xima da √°rvore, retorne n√≥ folha (A.M)
   	Se a esquerda do split for menor que o tamanho m√≠nimo:
   		A.N√≥_Esquerda = n√≥ folha (A.M.E)
   	Caso contr√°rio:
   		A.N√≥_Esquerda = obterSplit(A.M.E)
   		split (A.N√≥_Esquerda)
   	Se a direita do split for menor que o tamanho m√≠nimo:
   		A.N√≥_Direita = n√≥ folha (A.M.D)
   	Caso contr√°rio:
   		A.N√≥_Direita = obterSplit(A.M.D)
   		split (A.N√≥_Direita)
   ```

   Qual √© a complexidade deste algoritmo? Digamos que `L` √© o n√∫mero de linhas do dataset, `C` o total de *features*, `K` o n√∫mero de classes diferentes, e  `T` o total de √°rvores constru√≠das. Supondo que para determinar se um *Split* √© melhor do que outro, usamos o [*coeficiente Gini*](https://en.wikipedia.org/wiki/Gini_coefficient), que tem complexidade `O(L * K)`, a complexidade do algoritmo seria:

   ````
   Compl. de construir a √°rvore: N log( N )
   Compl. de cada n√≥: C * L * ( L + L * K ) ‚âÉ C * L¬≤ * K
   Resultado: O(CL¬≤K log( CL¬≤K ))
   ````

   Note que estamos olhando de maneira quadr√°tica pro *dataset*.

5. ### Implementa√ß√£o em Swift

   #### 5.1 Arrays vs Ponteiros

   A estrutura de dados `Array`, em Swift √© muito conveniente, mas muito lenta. Vamos fazer um *benchmark*?

   ```
   let bm = BenchmarkTest.init(count: 1000000)
   bm.begin()
   ```

   Vamos conferir os n√∫meros de acesso:

   ```
   Array Access: 			0.0430499911308289 s
   NSMutableArray Access: 	0.519761979579926 s
   Pointer Access: 		0.0407860279083252 s
   ```

   E os tempos de *alloc/dealloc*:

   ```
   Array Alloc: 				0.01119 s
   NSMutableArray Alloc: 		2.32907 s
   UnsafeMutablePointer Alloc: 0.00043 s
   ```

   Claro que usando ponteiros INSEGUROS, temos que tomar conta da nossa pr√≥pria mem√≥ria. Mas o ganho de desempenho deve compensar esse pre√ßo. Como usar arrays de ponteiros? Vamos ver:

   ```Swift
   // Em vez disso
   let a:Array<Int> = Array(repeating:Int(0), count:10)
   // faremos isso
   let b:UnsafeMutablePointer<Int> = UnsafeMutablePointer<Int>.allocate(capacity: 10 * MemoryLayout<Int>.size)
   // e para mudar o tamanho do array
   b = realloc(b, 20*MemoryLayout<Int>.size).assumingMemoryBound(to: Int.self)
   // e depois de usar
   b.deallocate(capacity: 10 * MemoryLayout<Int>.size)

   // Para pegar referencias de structs sem copiar valores nativos, em vez disso
   let a_copy = test
   // Faremos isso
   let b_copy = UnsafeRawPointer(Unmanaged.passUnretained(test).toOpaque())
   // E para acessar
   Unmanaged<Int>.fromOpaque(b_copy).takeUnretainedValue()
   ```

   Lembre-se que `realloc` √© uma opera√ß√£o cara. A implementa√ß√£o de `Array`, por exemplo, dobra o tamanho quando chegamos no limite. A regra de ouro √© sempre que poss√≠vel fazer um `loop` e calcular o tamanho novo do array, em vez de realocar a cada novo *append*.

   #### 5.2 Tipos gen√©ricos

   Outro detalhe importante quando trabalhamos com dados √© o tipo. Como o Random Forest n√£o √© um cara de grandes opera√ß√µes matem√°ticas, isso n√£o vai importar muito pro nosso caso, e podemos usar `Double` sem dor no peito. De qualquer modo, √© muito interessante que implementa√ß√µes de estruturas de dados para Aprendizado de M√°quina sejam gen√©ricas. [Apanhei um pouco](http://stackoverflow.com/questions/42696579/) pra deixar tudo gen√©rico, mas considero que o resultado ficou bem interessante. Veja exemplos das declara√ß√µes:

   ```swift
   protocol Numeric:Hashable, Comparable
   class Matrix<T:Numeric>
   class TreeNode<T:Numeric>
   protocol ClassifierAlgorithm {
       associatedtype NumericType:Numeric
   }
   class RandomForest<T:Numeric>: ClassifierAlgorithm {
       typealias NumericType = T
   }
   class CrossValidation<T:Numeric, U:ClassifierAlgorithm>: NSObject where U.NumericType == T
   ```

   #### 5.3 Opera√ß√µes paralelas com `Operation`

   No nosso algoritmo, nada impede que as √°rvores sejam constru√≠das paralelamente. Em termos de performance, com testes rasos usando `Operation`, o tempo de construir nove √°rvores de tr√™s em tr√™s √© um ter√ßo de construir de uma em uma. Pois, vamos ao que interessa, come√ßamos com um gerenciador de oper√°rios, tamb√©m conhecido como sindicato üòÇ:

   ```swift
   class PendingOperations {
       var queueName:String
       var concurrentOperations:Int
       init (queueName:String, concurrentOperations:Int) {
           self.queueName = queueName
           self.concurrentOperations = concurrentOperations
       }
       lazy var buildsInProgress = [NSIndexPath:Operation]()
       lazy var buildQueue:OperationQueue = {
           var queue = OperationQueue()
           queue.name = self.queueName
           queue.maxConcurrentOperationCount = self.concurrentOperations
           return queue
       }()
   }
   ```

   Uma classe oper√°ria oprimida pelo sistema:

   ```swift
   class TreeBuilder:Operation {    
       override func main() {
   		...
       }
   }
   ```

   E para convocar uma greve:

   ```
   for _ in 0..<self.treesCount {
   	let treeBuilder = TreeBuilder.init()
   	treeBuilder.completionBlock = {...}
   	self.pendingOperations.buildQueue.addOperation(treeBuilder)
   }
   ```

6. ### Valida√ß√£o Cruzada e *Overfitting*

   Como validar o nosso modelo na pr√°tica? √â comum ver em artigos da √°rea frases como `to evaluate our accuracy we used 10-fold cross-validation [...] `. Vamos explicar:

   **Acur√°cia** √© uma m√©trica comum para algoritmos de ML, basicamente, previs√µes corretas/n√∫mero de testes. Entenda:

   ````Swift
   private func accuracy(actual:Array<T>, predicted:Array<T>) -> Double {
   	let correct = zip(actual, predicted).reduce(0){ (a: Int, element) in
   		var accumulator = a
   		if element.0 == element.1 { accumulator += 1 }
   		return accumulator
   	}
   	return Double(correct)/Double(actual.count)
   }
   ````

   **Overfitting** √© o fen√¥meno que ocorre quando um modelo performa muito bem para para os dados de treino, e muito mal para os dados de teste. Veja um exemplo na seguinte imagem:

   ![]({{ site.baseurl }}/img/farris/2017/overfitting.jpg)

   A linha verde √© a fun√ß√£o que gerou os dados. A linha azul √© uma fun√ß√£o criada por uma regress√£o. Dado um novo ponto da linha verde, ser√° que o modelo azul vai predizer corretamente? *N√£o*.

   A criptonita do *overfitting* √© ter muitos dados. Quanto mais dados, melhor. *Sempre*.

   **Valida√ß√£o Cruzada (K-fold Cross Validation)** √© o conceito de dividir aleatoriamente o dataset em K subconjuntos de tamanho igual, e para cada subconjunto, usar ele de valida√ß√£o e os demais como teste. Entenda:

   ```swift
   let dataset:Array<T> = getDataset(), foldCount = 10
   let folds:Array<Array<T>> = crossValidationSplit(dataset: dataset, folds: foldCount)
   for fold in folds {
   	let trainData = datasetByRemovingFold(fold)
   	let testData = fold
   	algorithm.runClassifier(trainData,testData)
   }
   ```

   Valida√ß√£o cruzada ajuda tamb√©m a reduzir um fantasma chamado *overfitting*.

   Vamos avaliar nosso algoritmo? Usando os par√¢metros padr√£o, com 10 *folds*, temos:

   ```
   Fold 0 had accuracy 0.887876025524157
   Fold 1 had accuracy 0.906107566089335
   Fold 2 had accuracy 0.880583409298086
   Fold 3 had accuracy 0.86873290793072
   Fold 4 had accuracy 0.886052871467639
   Fold 5 had accuracy 0.896991795806746
   Fold 6 had accuracy 0.886052871467639
   Fold 7 had accuracy 0.864175022789426
   Fold 8 had accuracy 0.877848678213309
   Fold 9 had accuracy 0.88514129443938
   ```

   A acur√°cia m√©dia √© `0,883`. Ou seja, estamos predizento,em m√©dia, corretamente se 88% dos funcion√°rios se demitiram ou n√£o. Interessante n√©? Vamos olhar uma √°rvore constru√≠da:

   ![]({{ site.baseurl }}/img/farris/2017/tree.png)

   Vamos olhar mais de perto nossa classifica√ß√£o:

   |                            | N√£o se demitiu | Demitiu |
   |----------------------------|----------------|---------|
   | Achamos que n√£o se demitiu | 85%            | 12%     |
   | Achamos que se demitiu     | 0%             | 3%      |

   *Opa*. Parece que nosso classificador tem um vi√©s. Isso est√° acontecendo porque o dataset √© muito desbalanceado, ou seja, apenas 15% dos dados s√£o de funcion√°rios que pediram demiss√£o. Vamos mudar nosso sampling para usar mais esta classe (*subsampling*), ponderar as vari√°veis na hora de calcular o √≠ndice gini e na hora de predizer com o bagging, e mudar nossa m√©trica pra um indicador que lide melhor com os dados desbalanceados ([kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa)), como sugerido [no famoso artigo 666 de Berkeley](http://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf):

   >For each iteration in random forest, draw a bootstrap sample from the minority class. Randomly draw
   the same number of cases, with replacement, from the majority class [...] Since the RF classifier tends to be biased towards the majority class, we shall place a heavier penalty on misclassifying the minority class. We assign a weight to each class, with the minority class given larger weight




7. ### Conclus√£o

   Nessa nossa breve jornada juntos, implementamos um classificador altamente pr√°tico, com um desempenho aceit√°vel. Entendemos como lidar com dados, e a avaliar nossos modelos. Vimos como usar ponteiros, generics, e paralelizar opera√ß√µes em Swift 3. Descobrimos o poss√≠vel perfil de quem pede demiss√£o. Aprendemos como examinar o resultado do classificador.
   Obrigado pela leitura. At√© a pr√≥xima!
   O c√≥digo deste artigo pode ser encontrado [neste reposit√≥rio](https://github.com/luksfarris/SwiftRandomForest).

> Lucas Farris come√ßou com programa√ß√£o em 2006, entrou no mercado mobile em 2011, em 2014 se formou em Ci√™ncia da Computa√ß√£o na Unicamp. Atualmente trabalha na Pol√¥nia, onde cuida de uma planta robo chamada *–°–∞—à–∞*.
